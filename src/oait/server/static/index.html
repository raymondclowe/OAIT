<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OAIT - Observational AI Tutor</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }
        
        h1 {
            color: #667eea;
            margin-bottom: 10px;
        }
        
        .subtitle {
            color: #666;
            margin-bottom: 30px;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }
        
        button {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
        }
        
        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .btn-primary {
            background: #667eea;
            color: white;
        }
        
        .btn-danger {
            background: #f56565;
            color: white;
        }
        
        .btn-success {
            background: #48bb78;
            color: white;
        }
        
        .status {
            padding: 12px;
            border-radius: 8px;
            margin-bottom: 20px;
            font-weight: 500;
        }
        
        .status.connected {
            background: #c6f6d5;
            color: #22543d;
        }
        
        .status.disconnected {
            background: #fed7d7;
            color: #742a2a;
        }
        
        .workspace {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }
        
        .panel {
            background: #f7fafc;
            border-radius: 12px;
            padding: 20px;
        }
        
        .panel h2 {
            color: #2d3748;
            margin-bottom: 15px;
            font-size: 18px;
        }
        
        #whiteboard {
            width: 100%;
            height: 400px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            background: white;
        }
        
        .transcript-area, .ai-responses {
            height: 400px;
            overflow-y: auto;
            background: white;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            padding: 15px;
        }
        
        .transcript-item, .ai-item {
            margin-bottom: 12px;
            padding: 10px;
            border-radius: 6px;
            line-height: 1.5;
        }
        
        .transcript-item {
            background: #ebf8ff;
            border-left: 3px solid #3182ce;
        }
        
        .ai-item {
            background: #f0fff4;
            border-left: 3px solid #38a169;
        }
        
        .timestamp {
            color: #718096;
            font-size: 12px;
            margin-bottom: 4px;
        }
        
        @media (max-width: 768px) {
            .workspace {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéì OAIT - Observational AI Tutor</h1>
        <p class="subtitle">AI-powered tutoring with continuous observation and intelligent intervention</p>
        
        <div class="controls">
            <input type="text" id="studentId" placeholder="Student ID" style="padding: 12px; border: 2px solid #e2e8f0; border-radius: 8px; flex: 1; min-width: 200px;">
            <button id="startSession" class="btn-primary">Start Session</button>
            <button id="stopSession" class="btn-danger" disabled>Stop Session</button>
            <button id="startAudio" class="btn-success" disabled>Start Audio</button>
            <button id="stopAudio" class="btn-danger" disabled>Stop Audio</button>
        </div>
        
        <div id="status" class="status disconnected">
            ‚ö´ Disconnected
        </div>
        
        <div class="workspace">
            <div class="panel">
                <h2>üìù Whiteboard</h2>
                <canvas id="whiteboard"></canvas>
            </div>
            
            <div class="panel">
                <h2>üí¨ Transcript</h2>
                <div id="transcript" class="transcript-area">
                    <p style="color: #a0aec0; text-align: center; margin-top: 100px;">
                        Start speaking to see transcripts...
                    </p>
                </div>
            </div>
        </div>
        
        <div class="panel">
            <h2>ü§ñ AI Responses</h2>
            <div id="aiResponses" class="ai-responses">
                <p style="color: #a0aec0; text-align: center; margin-top: 50px;">
                    AI responses will appear here...
                </p>
            </div>
        </div>
    </div>
    
    <script>
        let ws = null;
        let sessionId = null;
        let audioContext = null;
        let mediaStream = null;
        let isRecording = false;
        let canvas = null;
        let ctx = null;
        
        const statusDiv = document.getElementById('status');
        const startSessionBtn = document.getElementById('startSession');
        const stopSessionBtn = document.getElementById('stopSession');
        const startAudioBtn = document.getElementById('startAudio');
        const stopAudioBtn = document.getElementById('stopAudio');
        const studentIdInput = document.getElementById('studentId');
        const transcriptDiv = document.getElementById('transcript');
        const aiResponsesDiv = document.getElementById('aiResponses');
        
        // Initialize canvas
        canvas = document.getElementById('whiteboard');
        ctx = canvas.getContext('2d');
        canvas.width = canvas.offsetWidth;
        canvas.height = canvas.offsetHeight;
        
        // Simple drawing functionality
        let isDrawing = false;
        let lastX = 0;
        let lastY = 0;
        
        canvas.addEventListener('mousedown', (e) => {
            isDrawing = true;
            [lastX, lastY] = [e.offsetX, e.offsetY];
        });
        
        canvas.addEventListener('mousemove', (e) => {
            if (!isDrawing) return;
            ctx.beginPath();
            ctx.moveTo(lastX, lastY);
            ctx.lineTo(e.offsetX, e.offsetY);
            ctx.strokeStyle = '#2d3748';
            ctx.lineWidth = 2;
            ctx.lineCap = 'round';
            ctx.stroke();
            [lastX, lastY] = [e.offsetX, e.offsetY];
        });
        
        canvas.addEventListener('mouseup', () => {
            isDrawing = false;
        });
        
        canvas.addEventListener('mouseout', () => {
            isDrawing = false;
        });
        
        function sendCanvasFrame() {
            if (!ws || ws.readyState !== WebSocket.OPEN) return;
            
            canvas.toBlob((blob) => {
                const reader = new FileReader();
                reader.onload = () => {
                    const base64 = reader.result.split(',')[1];
                    ws.send(JSON.stringify({
                        type: 'video',
                        data: base64
                    }));
                };
                reader.readAsDataURL(blob);
            }, 'image/png');
        }
        
        // Send canvas frame every 3 seconds
        setInterval(() => {
            if (ws && ws.readyState === WebSocket.OPEN) {
                sendCanvasFrame();
            }
        }, 3000);
        
        startSessionBtn.addEventListener('click', async () => {
            const studentId = studentIdInput.value.trim();
            if (!studentId) {
                alert('Please enter a student ID');
                return;
            }
            
            try {
                // Start session
                const response = await fetch(`/session/start?student_id=${studentId}`, {
                    method: 'POST'
                });
                const data = await response.json();
                sessionId = data.session_id;
                
                // Connect WebSocket
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                ws = new WebSocket(`${protocol}//${window.location.host}/ws/${sessionId}`);
                
                ws.onopen = () => {
                    updateStatus(true);
                    startSessionBtn.disabled = true;
                    stopSessionBtn.disabled = false;
                    startAudioBtn.disabled = false;
                    studentIdInput.disabled = true;
                };
                
                ws.onmessage = (event) => {
                    const message = JSON.parse(event.data);
                    
                    if (message.type === 'transcript') {
                        addTranscript(message.text, message.timestamp);
                    } else if (message.type === 'ai_response') {
                        addAIResponse(message.text, message.strategy);
                        speakText(message.text);
                    }
                };
                
                ws.onclose = () => {
                    updateStatus(false);
                    startSessionBtn.disabled = false;
                    stopSessionBtn.disabled = true;
                    startAudioBtn.disabled = true;
                    stopAudioBtn.disabled = true;
                    studentIdInput.disabled = false;
                };
                
                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                };
                
            } catch (error) {
                console.error('Error starting session:', error);
                alert('Failed to start session');
            }
        });
        
        stopSessionBtn.addEventListener('click', async () => {
            if (ws) {
                ws.close();
            }
            
            if (sessionId) {
                try {
                    await fetch(`/session/${sessionId}/stop`, {
                        method: 'POST'
                    });
                } catch (error) {
                    console.error('Error stopping session:', error);
                }
            }
            
            sessionId = null;
        });
        
        startAudioBtn.addEventListener('click', async () => {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(mediaStream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                processor.onaudioprocess = (e) => {
                    if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;
                    
                    const audioData = e.inputBuffer.getChannelData(0);
                    const audioBlob = float32ToWav(audioData, audioContext.sampleRate);
                    
                    const reader = new FileReader();
                    reader.onload = () => {
                        const base64 = reader.result.split(',')[1];
                        ws.send(JSON.stringify({
                            type: 'audio',
                            data: base64
                        }));
                    };
                    reader.readAsDataURL(audioBlob);
                };
                
                isRecording = true;
                startAudioBtn.disabled = true;
                stopAudioBtn.disabled = false;
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                alert('Failed to access microphone');
            }
        });
        
        stopAudioBtn.addEventListener('click', () => {
            isRecording = false;
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
            }
            if (audioContext) {
                audioContext.close();
            }
            startAudioBtn.disabled = false;
            stopAudioBtn.disabled = true;
        });
        
        function updateStatus(connected) {
            if (connected) {
                statusDiv.textContent = 'üü¢ Connected';
                statusDiv.className = 'status connected';
            } else {
                statusDiv.textContent = '‚ö´ Disconnected';
                statusDiv.className = 'status disconnected';
            }
        }
        
        function addTranscript(text, timestamp) {
            const time = new Date(timestamp).toLocaleTimeString();
            const item = document.createElement('div');
            item.className = 'transcript-item';
            item.innerHTML = `
                <div class="timestamp">${time}</div>
                <div>${text}</div>
            `;
            transcriptDiv.prepend(item);
        }
        
        function addAIResponse(text, strategy) {
            const time = new Date().toLocaleTimeString();
            const item = document.createElement('div');
            item.className = 'ai-item';
            item.innerHTML = `
                <div class="timestamp">${time} ${strategy ? `[${strategy}]` : ''}</div>
                <div>${text}</div>
            `;
            aiResponsesDiv.prepend(item);
        }
        
        function speakText(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 0.9;
            utterance.pitch = 1.0;
            window.speechSynthesis.speak(utterance);
        }
        
        function float32ToWav(float32Array, sampleRate) {
            const buffer = new ArrayBuffer(44 + float32Array.length * 2);
            const view = new DataView(buffer);
            
            // WAV header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + float32Array.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, 'data');
            view.setUint32(40, float32Array.length * 2, true);
            
            // Audio data
            let offset = 44;
            for (let i = 0; i < float32Array.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            
            return new Blob([buffer], { type: 'audio/wav' });
        }
        
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }
    </script>
</body>
</html>
